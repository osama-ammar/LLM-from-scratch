
training:
  batch_size: 128
  block_size: 64
  n_embd: 384
  n_head: 8
  n_layer: 8
  dropout: 0.2
  device: "cuda"

optimizer:
  lr: 0.001
  weight_decay: 0.01

scheduler:
  step_size: 10
  gamma: 0.1

data:
  train_data_path: "data/output_train.txt"
  val_data_path: "data/output_val.txt"
  test_data_path: "data/test.txt"
  unique_vocab: "data/vocab.txt"

model:
  vocab_size: 30522
  max_position_embeddings: 512
  type_vocab_size: 2
  initializer_range: 0.02

training_params:
  num_epochs: 10
  log_interval: 100
  save_interval: 1
  output_dir: "model_output/"










